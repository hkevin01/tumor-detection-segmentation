{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fda24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Qualitative Review: Task01 Brain Tumor Segmentation\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook provides qualitative assessment of trained brain tumor segmentation models.\\n\",\n",
    "    \"We'll load a trained model, run inference on validation samples, and visualize:\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Original multi-modal images\\n\",\n",
    "    \"- Ground truth segmentations\\n\",\n",
    "    \"- Model predictions\\n\",\n",
    "    \"- Probability maps for tumor classes\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Setup and Configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import json\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from monai.data import decollate_batch\\n\",\n",
    "    \"from monai.inferers import SlidingWindowInferer\\n\",\n",
    "    \"from monai.transforms import AsDiscrete\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add project root to path\\n\",\n",
    "    \"project_root = Path().cwd().parent if Path().cwd().name == 'notebooks' else Path().cwd()\\n\",\n",
    "    \"sys.path.append(str(project_root))\\n\",\n",
    "    \"\\n\",\n",
    "    \"from src.data.loaders_monai import load_monai_decathlon\\n\",\n",
    "    \"from src.data.transforms_presets import get_transforms_brats_like\\n\",\n",
    "    \"from src.training.train_enhanced import build_model_from_cfg, get_device\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Project root: {project_root}\\\")\\n\",\n",
    "    \"print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Configuration\\n\",\n",
    "    \"MODEL_PATH = \\\"models/unetr/best.pt\\\"\\n\",\n",
    "    \"CONFIG_PATH = \\\"config/recipes/unetr_multimodal.json\\\"\\n\",\n",
    "    \"DATASET_CONFIG_PATH = \\\"config/datasets/msd_task01_brain.json\\\"\\n\",\n",
    "    \"OUTPUT_DIR = \\\"reports/qualitative\\\"\\n\",\n",
    "    \"N_SAMPLES = 2  # Number of validation samples to analyze\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Device setup\\n\",\n",
    "    \"device = get_device(\\\"auto\\\")\\n\",\n",
    "    \"print(f\\\"Using device: {device}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create output directory\\n\",\n",
    "    \"output_dir = Path(OUTPUT_DIR)\\n\",\n",
    "    \"output_dir.mkdir(parents=True, exist_ok=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load Configuration and Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load configurations\\n\",\n",
    "    \"with open(CONFIG_PATH, 'r') as f:\\n\",\n",
    "    \"    config = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"with open(DATASET_CONFIG_PATH, 'r') as f:\\n\",\n",
    "    \"    dataset_config = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Model config:\\\")\\n\",\n",
    "    \"print(f\\\"  Architecture: {config.get('model', {}).get('arch', 'unetr')}\\\")\\n\",\n",
    "    \"print(f\\\"  Image size: {config.get('model', {}).get('img_size', [128, 128, 128])}\\\")\\n\",\n",
    "    \"print(f\\\"  Output channels: {config.get('model', {}).get('out_channels', 2)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nDataset config:\\\")\\n\",\n",
    "    \"print(f\\\"  Dataset: {dataset_config.get('dataset_id', 'Task01_BrainTumour')}\\\")\\n\",\n",
    "    \"print(f\\\"  Transforms: {dataset_config.get('transforms', 'brats_like')}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup transforms and load validation data\\n\",\n",
    "    \"spacing = tuple(dataset_config.get(\\\"spacing\\\", (1.0, 1.0, 1.0)))\\n\",\n",
    "    \"transforms_train, transforms_val = get_transforms_brats_like(spacing=spacing)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load validation dataset\\n\",\n",
    "    \"val_data = load_monai_decathlon(\\n\",\n",
    "    \"    root_dir=\\\"data/msd\\\",\\n\",\n",
    "    \"    task=\\\"Task01_BrainTumour\\\",\\n\",\n",
    "    \"    section=\\\"validation\\\",\\n\",\n",
    "    \"    download=True,\\n\",\n",
    "    \"    cache_rate=0.0,\\n\",\n",
    "    \"    num_workers=2,\\n\",\n",
    "    \"    transform=transforms_val,\\n\",\n",
    "    \"    batch_size=1,\\n\",\n",
    "    \"    pin_memory=False,\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"val_loader = val_data[\\\"dataloader\\\"]\\n\",\n",
    "    \"print(f\\\"Validation dataset loaded with {len(val_loader)} samples\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load Trained Model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Determine model parameters from validation data\\n\",\n",
    "    \"sample_batch = next(iter(val_loader))\\n\",\n",
    "    \"sample_image = sample_batch[\\\"image\\\"]\\n\",\n",
    "    \"in_channels = sample_image.shape[1]\\n\",\n",
    "    \"out_channels = config.get(\\\"model\\\", {}).get(\\\"out_channels\\\", 2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Input channels: {in_channels}\\\")\\n\",\n",
    "    \"print(f\\\"Output channels: {out_channels}\\\")\\n\",\n",
    "    \"print(f\\\"Sample image shape: {sample_image.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Build and load model\\n\",\n",
    "    \"model = build_model_from_cfg(config, in_channels, out_channels).to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load trained weights\\n\",\n",
    "    \"if Path(MODEL_PATH).exists():\\n\",\n",
    "    \"    checkpoint = torch.load(MODEL_PATH, map_location=device)\\n\",\n",
    "    \"    if \\\"model\\\" in checkpoint:\\n\",\n",
    "    \"        model.load_state_dict(checkpoint[\\\"model\\\"])\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        model.load_state_dict(checkpoint)\\n\",\n",
    "    \"    print(f\\\"Model loaded from {MODEL_PATH}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(f\\\"Warning: Model file not found at {MODEL_PATH}\\\")\\n\",\n",
    "    \"    print(\\\"Using randomly initialized model for demonstration\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.eval()\\n\",\n",
    "    \"print(\\\"Model ready for inference\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Setup Inference Components\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Setup sliding window inferer\\n\",\n",
    "    \"roi_size = tuple(config.get(\\\"model\\\", {}).get(\\\"img_size\\\", [128, 128, 128]))\\n\",\n",
    "    \"inferer = SlidingWindowInferer(\\n\",\n",
    "    \"    roi_size=roi_size,\\n\",\n",
    "    \"    sw_batch_size=1,\\n\",\n",
    "    \"    overlap=0.25,\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Setup post-processing transforms\\n\",\n",
    "    \"post_pred = AsDiscrete(argmax=True, to_onehot=out_channels)\\n\",\n",
    "    \"post_label = AsDiscrete(to_onehot=out_channels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Sliding window ROI size: {roi_size}\\\")\\n\",\n",
    "    \"print(f\\\"Inference setup complete\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Visualization Functions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def plot_multi_slice_comparison(image, gt_mask, pred_mask, prob_map, case_name, save_path=None):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Plot multi-slice comparison showing image, ground truth, prediction, and probability map.\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    Args:\\n\",\n",
    "    \"        image: (C, H, W, D) input image tensor\\n\",\n",
    "    \"        gt_mask: (H, W, D) ground truth mask\\n\",\n",
    "    \"        pred_mask: (H, W, D) prediction mask\\n\",\n",
    "    \"        prob_map: (H, W, D) probability map for tumor class\\n\",\n",
    "    \"        case_name: Case identifier for title\\n\",\n",
    "    \"        save_path: Optional path to save the figure\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    # Use first channel as background (T1)\\n\",\n",
    "    \"    img = image[0].cpu().numpy()\\n\",\n",
    "    \"    gt = gt_mask.cpu().numpy()\\n\",\n",
    "    \"    pred = pred_mask.cpu().numpy()\\n\",\n",
    "    \"    prob = prob_map.cpu().numpy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Select slices (25%, 50%, 75% depth)\\n\",\n",
    "    \"    _, _, D = img.shape\\n\",\n",
    "    \"    slices = [D // 4, D // 2, 3 * D // 4]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, axes = plt.subplots(4, 3, figsize=(15, 16))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, z in enumerate(slices):\\n\",\n",
    "    \"        # Normalize image slice\\n\",\n",
    "    \"        img_slice = img[..., z]\\n\",\n",
    "    \"        img_slice = (img_slice - img_slice.min()) / (img_slice.max() - img_slice.min() + 1e-8)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        gt_slice = gt[..., z]\\n\",\n",
    "    \"        pred_slice = pred[..., z]\\n\",\n",
    "    \"        prob_slice = prob[..., z]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Row 0: Original image\\n\",\n",
    "    \"        axes[0, i].imshow(img_slice, cmap='gray')\\n\",\n",
    "    \"        axes[0, i].set_title(f'T1 Image - Slice {z}/{D-1}')\\n\",\n",
    "    \"        axes[0, i].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Row 1: Ground truth overlay\\n\",\n",
    "    \"        axes[1, i].imshow(img_slice, cmap='gray')\\n\",\n",
    "    \"        axes[1, i].imshow(np.ma.masked_where(gt_slice == 0, gt_slice), \\n\",\n",
    "    \"                         cmap='Greens', alpha=0.5)\\n\",\n",
    "    \"        axes[1, i].set_title(f'Ground Truth - Slice {z}')\\n\",\n",
    "    \"        axes[1, i].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Row 2: Prediction overlay\\n\",\n",
    "    \"        axes[2, i].imshow(img_slice, cmap='gray')\\n\",\n",
    "    \"        axes[2, i].imshow(np.ma.masked_where(pred_slice == 0, pred_slice), \\n\",\n",
    "    \"                         cmap='Reds', alpha=0.5)\\n\",\n",
    "    \"        axes[2, i].set_title(f'Prediction - Slice {z}')\\n\",\n",
    "    \"        axes[2, i].axis('off')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Row 3: Probability map\\n\",\n",
    "    \"        axes[3, i].imshow(img_slice, cmap='gray')\\n\",\n",
    "    \"        prob_overlay = axes[3, i].imshow(\\n\",\n",
    "    \"            np.ma.masked_where(prob_slice < 0.1, prob_slice), \\n\",\n",
    "    \"            cmap='hot', alpha=0.7, vmin=0, vmax=1\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        axes[3, i].set_title(f'Probability Map - Slice {z}')\\n\",\n",
    "    \"        axes[3, i].axis('off')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Add colorbar for probability map\\n\",\n",
    "    \"    cbar = plt.colorbar(prob_overlay, ax=axes[3, :], orientation='horizontal', \\n\",\n",
    "    \"                       fraction=0.05, pad=0.1)\\n\",\n",
    "    \"    cbar.set_label('Tumor Probability')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.suptitle(f'Qualitative Analysis: {case_name}', fontsize=16, y=0.98)\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if save_path:\\n\",\n",
    "    \"        plt.savefig(save_path, dpi=150, bbox_inches='tight')\\n\",\n",
    "    \"        print(f\\\"Figure saved to: {save_path}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"def calculate_dice_score(pred, gt):\\n\",\n",
    "    \"    \\\"\\\"\\\"Calculate Dice coefficient between prediction and ground truth.\\\"\\\"\\\"\\n\",\n",
    "    \"    pred_flat = pred.flatten()\\n\",\n",
    "    \"    gt_flat = gt.flatten()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    intersection = (pred_flat * gt_flat).sum()\\n\",\n",
    "    \"    total = pred_flat.sum() + gt_flat.sum()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if total == 0:\\n\",\n",
    "    \"        return 1.0  # Both empty\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    dice = (2.0 * intersection) / total\\n\",\n",
    "    \"    return dice\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Run Qualitative Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run inference on validation samples\\n\",\n",
    "    \"results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"with torch.no_grad():\\n\",\n",
    "    \"    for i, batch in enumerate(val_loader):\\n\",\n",
    "    \"        if i >= N_SAMPLES:\\n\",\n",
    "    \"            break\\n\",\n",
    "    \"            \\n\",\n",
    "    \"        print(f\\\"\\\\n=== Processing sample {i+1}/{N_SAMPLES} ===\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get batch data\\n\",\n",
    "    \"        images = batch[\\\"image\\\"].to(device)  # (1, C, H, W, D)\\n\",\n",
    "    \"        labels = batch[\\\"label\\\"].to(device)  # (1, 1, H, W, D)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Run inference\\n\",\n",
    "    \"        logits = inferer(images, model)  # (1, out_channels, H, W, D)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get probabilities and predictions\\n\",\n",
    "    \"        probs = torch.softmax(logits, dim=1)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Post-process predictions and labels\\n\",\n",
    "    \"        pred_list = [post_pred(p) for p in decollate_batch(logits)]\\n\",\n",
    "    \"        gt_list = [post_label(l) for l in decollate_batch(labels)]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Extract tensors (remove batch dimension)\\n\",\n",
    "    \"        image_tensor = images[0]  # (C, H, W, D)\\n\",\n",
    "    \"        pred_tensor = pred_list[0]  # (out_channels, H, W, D)\\n\",\n",
    "    \"        gt_tensor = gt_list[0]  # (out_channels, H, W, D)\\n\",\n",
    "    \"        prob_tensor = probs[0]  # (out_channels, H, W, D)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get class 1 (tumor) masks and probabilities\\n\",\n",
    "    \"        if out_channels > 1:\\n\",\n",
    "    \"            pred_mask = pred_tensor[1]  # (H, W, D)\\n\",\n",
    "    \"            gt_mask = gt_tensor[1]  # (H, W, D)\\n\",\n",
    "    \"            prob_map = prob_tensor[1]  # (H, W, D)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            pred_mask = pred_tensor[0]\\n\",\n",
    "    \"            gt_mask = gt_tensor[0]\\n\",\n",
    "    \"            prob_map = prob_tensor[0]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Calculate metrics\\n\",\n",
    "    \"        dice_score = calculate_dice_score(\\n\",\n",
    "    \"            pred_mask.cpu().numpy(), \\n\",\n",
    "    \"            gt_mask.cpu().numpy()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Calculate volume statistics\\n\",\n",
    "    \"        gt_volume = gt_mask.sum().item()\\n\",\n",
    "    \"        pred_volume = pred_mask.sum().item()\\n\",\n",
    "    \"        max_prob = prob_map.max().item()\\n\",\n",
    "    \"        mean_prob = prob_map.mean().item()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        print(f\\\"Dice Score: {dice_score:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"GT Volume: {gt_volume:.0f} voxels\\\")\\n\",\n",
    "    \"        print(f\\\"Pred Volume: {pred_volume:.0f} voxels\\\")\\n\",\n",
    "    \"        print(f\\\"Max Probability: {max_prob:.4f}\\\")\\n\",\n",
    "    \"        print(f\\\"Mean Probability: {mean_prob:.4f}\\\")\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Store results\\n\",\n",
    "    \"        case_name = f\\\"Case_{i+1:02d}\\\"\\n\",\n",
    "    \"        results.append({\\n\",\n",
    "    \"            'case_name': case_name,\\n\",\n",
    "    \"            'dice_score': dice_score,\\n\",\n",
    "    \"            'gt_volume': gt_volume,\\n\",\n",
    "    \"            'pred_volume': pred_volume,\\n\",\n",
    "    \"            'max_prob': max_prob,\\n\",\n",
    "    \"            'mean_prob': mean_prob,\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Create visualization\\n\",\n",
    "    \"        save_path = output_dir / f\\\"{case_name}_qualitative_analysis.png\\\"\\n\",\n",
    "    \"        plot_multi_slice_comparison(\\n\",\n",
    "    \"            image_tensor, gt_mask, pred_mask, prob_map, \\n\",\n",
    "    \"            case_name, save_path\\n\",\n",
    "    \"        )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate summary statistics\\n\",\n",
    "    \"if results:\\n\",\n",
    "    \"    dice_scores = [r['dice_score'] for r in results]\\n\",\n",
    "    \"    mean_dice = np.mean(dice_scores)\\n\",\n",
    "    \"    std_dice = np.std(dice_scores)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n=== SUMMARY STATISTICS ===\\\")\\n\",\n",
    "    \"    print(f\\\"Number of cases analyzed: {len(results)}\\\")\\n\",\n",
    "    \"    print(f\\\"Mean Dice Score: {mean_dice:.4f} Â± {std_dice:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Min Dice Score: {min(dice_scores):.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Max Dice Score: {max(dice_scores):.4f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create summary table\\n\",\n",
    "    \"    print(\\\"\\\\n=== DETAILED RESULTS ===\\\")\\n\",\n",
    "    \"    print(f\\\"{'Case':<8} {'Dice':<8} {'GT Vol':<8} {'Pred Vol':<10} {'Max Prob':<10} {'Mean Prob':<10}\\\")\\n\",\n",
    "    \"    print(\\\"-\\\" * 60)\\n\",\n",
    "    \"    for r in results:\\n\",\n",
    "    \"        print(f\\\"{r['case_name']:<8} {r['dice_score']:<8.4f} {r['gt_volume']:<8.0f} \\\"\\n\",\n",
    "    \"              f\\\"{r['pred_volume']:<10.0f} {r['max_prob']:<10.4f} {r['mean_prob']:<10.4f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Save results to JSON\\n\",\n",
    "    \"    results_file = output_dir / \\\"qualitative_analysis_results.json\\\"\\n\",\n",
    "    \"    with open(results_file, 'w') as f:\\n\",\n",
    "    \"        json.dump({\\n\",\n",
    "    \"            'summary': {\\n\",\n",
    "    \"                'n_cases': len(results),\\n\",\n",
    "    \"                'mean_dice': mean_dice,\\n\",\n",
    "    \"                'std_dice': std_dice,\\n\",\n",
    "    \"                'min_dice': min(dice_scores),\\n\",\n",
    "    \"                'max_dice': max(dice_scores),\\n\",\n",
    "    \"            },\\n\",\n",
    "    \"            'cases': results\\n\",\n",
    "    \"        }, f, indent=2)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nResults saved to: {results_file}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No results to summarize.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This qualitative analysis provides insights into the model's learned behavior:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Segmentation Quality**: The Dice scores indicate overall segmentation accuracy\\n\",\n",
    "    \"2. **Spatial Consistency**: Multi-slice views show how well the model maintains spatial coherence\\n\",\n",
    "    \"3. **Confidence Assessment**: Probability maps reveal model uncertainty and confidence regions\\n\",\n",
    "    \"4. **Volume Estimation**: Comparison of predicted vs ground truth volumes shows systematic biases\\n\",\n",
    "    \"\\n\",\n",
    "    \"The visualizations are saved in the `reports/qualitative/` directory for further analysis and comparison across different model configurations.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
